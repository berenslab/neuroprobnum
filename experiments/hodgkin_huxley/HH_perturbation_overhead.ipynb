{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hodgkin-Huxley | Overhead\n",
    "\n",
    "Compute run times and computational overhead of perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import product as itproduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path as sys_path\n",
    "from os.path import abspath as os_path_abspath\n",
    "sys_path.append(os_path_abspath('..'))\n",
    "import addpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim_utils\n",
    "import math_utils\n",
    "import frame_utils\n",
    "import metric_utils\n",
    "import plot_utils as pltu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hodgkin_huxley\n",
    "t0, tmax = 0, 100\n",
    "neuron = hodgkin_huxley.neuron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_onset, stim_offset = 10, tmax-10\n",
    "stims = [\n",
    "    stim_utils.Istim(Iamp=0.15, onset=stim_onset, offset=stim_offset, name='Step'),\n",
    "]\n",
    "for stim in stims: stim.plot(t0=t0, tmax=tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator_HH import data_generator_HH\n",
    "from copy import deepcopy\n",
    "\n",
    "gens = {}\n",
    "\n",
    "for stim in stims:\n",
    "    \n",
    "    neuron = deepcopy(neuron)\n",
    "    neuron.get_Istim_at_t = stim.get_I_at_t\n",
    "    \n",
    "    gens[stim] = data_generator_HH(\n",
    "        t0=t0, tmax=tmax, t_eval_adaptive=None, max_step=1.0,\n",
    "        return_vars=['ys'],\n",
    "        model=neuron, y0=neuron.compute_yinf(-65), thresh=0.0,\n",
    "        n_samples=100, n_parallel=20,\n",
    "        gen_det_sols=False, gen_acc_sols=False,\n",
    "        base_folder='_data/pert_overhead'\n",
    "    )\n",
    "    gens[stim].update_subfoldername(stim=stim.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pert_method, adaptive, methods, step_params, pert_params\n",
    "solver_params = [\n",
    "    ('conrad', 0, ['FE', 'EE', 'EEMP', 'RKBS', 'RKCK', 'RKDP'], [0.01], [1]),\n",
    "    ('conrad', 1, ['RKBS', 'RKCK', 'RKDP'], [1e-4], [1]),\n",
    "    \n",
    "    ('abdulle', 0, ['FE', 'EE', 'EEMP', 'RKBS', 'RKCK', 'RKDP'], [0.01], [0.1]),    \n",
    "    ('abdulle', 1, ['RKBS', 'RKCK', 'RKDP'], [1e-4], [0.1]),\n",
    "    \n",
    "    ('abdulle_ln', 0, ['FE', 'EE', 'EEMP', 'RKBS', 'RKCK', 'RKDP'], [0.01], [0.1]),    \n",
    "    ('abdulle_ln', 1, ['RKBS', 'RKCK', 'RKDP'], [1e-4], [0.1]),\n",
    "\n",
    "    (None, 0, ['FE', 'EE', 'EEMP', 'RKBS', 'RKCK', 'RKDP'], [0.01], ['None']),\n",
    "    (None, 1, ['RKBS', 'RKCK', 'RKDP'], [1e-4], ['None']),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stim, gen in gens.items():\n",
    "    \n",
    "    print('----------------------------------------------------------')\n",
    "    print(stim, ':', gen.subfoldername)\n",
    "    print('----------------------------------------------------------')   \n",
    "    \n",
    "    for pert_method, adaptive, methods, step_params, pert_params in solver_params:\n",
    "        for step_param, method, pert_param in itproduct(step_params, methods, pert_params):\n",
    "            gen.gen_and_save_data(\n",
    "                method=method, adaptive=adaptive, step_param=step_param,\n",
    "                pert_method=pert_method, pert_param=pert_param, allowgenerror=False,\n",
    "                overwrite=False, \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import data_loader\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for stim, gen in gens.items():\n",
    "    stim_df = data_loader(gen).load_data2dataframe(\n",
    "        solver_params, drop_traces=False, MAEs=False, allowgenerror=True\n",
    "    )\n",
    "    metric_utils.add_det_nODEcalls(stim_df, T=gen.tmax-gen.t0)\n",
    "    stim_df['stimfun'] = stim\n",
    "    stim_df['stim'] = stim.name\n",
    "    \n",
    "    df = df.append(stim_df, ignore_index=True)\n",
    "    \n",
    "df.pert_method = df.pert_method.fillna(value='det.')\n",
    "df = df[['method', 'adaptive', 'pert_method', 'stim', 'run_times']] # Drop some columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = {\n",
    "    'solver': [], 'stim': [], 'method': [], 'adaptive': [],\n",
    "    'abdulle_rel_run_times': [],\n",
    "    'abdulleln_rel_run_times': [],  \n",
    "    'conrad_rel_run_times': [],\n",
    "}\n",
    "\n",
    "for (method, adaptive, stim), group in df.groupby(by=['method', 'adaptive', 'stim']):\n",
    "    assert group.shape[0] == 4, group.shape[0]\n",
    "    assert group.pert_method.nunique() == 4   \n",
    "    \n",
    "    plot_df['solver'].append(pltu.method2label(method=method, adaptive=adaptive))\n",
    "    plot_df['method'].append(method)\n",
    "    plot_df['adaptive'].append(adaptive)\n",
    "    plot_df['stim'].append(stim)\n",
    "    \n",
    "    plot_df['abdulle_rel_run_times'].append(\n",
    "        group.run_times[group.pert_method == 'abdulle'].iloc[0] / group.run_times[group.pert_method == 'det.'].iloc[0])\n",
    "    plot_df['abdulleln_rel_run_times'].append(\n",
    "        group.run_times[group.pert_method == 'abdulle_ln'].iloc[0] / group.run_times[group.pert_method == 'det.'].iloc[0])\n",
    "    plot_df['conrad_rel_run_times'].append(\n",
    "        group.run_times[group.pert_method == 'conrad'].iloc[0] / group.run_times[group.pert_method == 'det.'].iloc[0])\n",
    "    \n",
    "plot_df = pd.DataFrame(plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = pltu.subplots(1,1,ysizerow=1.4,squeeze=False)\n",
    "pltu.move_xaxis_outward(axs, scale=3)\n",
    "\n",
    "ax = axs.flat[0]\n",
    "\n",
    "### Plot data ###\n",
    "for i, (data, pert_method) in enumerate(zip(\n",
    "    [plot_df.conrad_rel_run_times, plot_df.abdulle_rel_run_times, plot_df.abdulleln_rel_run_times],\n",
    "    ['conrad', 'abdulle', 'abdulle_ln']\n",
    ")):\n",
    "\n",
    "    positions = pltu.get_x_positions(n_positions=plot_df.shape[0], idx=i, n_idxs=3)\n",
    "\n",
    "    if pert_method == 'conrad':\n",
    "        ttl = 'State pert.'\n",
    "    elif pert_method == 'abdulle':\n",
    "        ttl = 'Step-size pert. uniform'\n",
    "    elif pert_method == 'abdulle_ln':\n",
    "        ttl = 'Step-size pert. log-normal'\n",
    "    \n",
    "    pltu.plot_percentiles(\n",
    "        ax=ax, data=list(data), positions=positions, connect=False,\n",
    "        color=pltu.neuron2color(i), marker=['X', 'P', 'o'][i],\n",
    "        mean_kw=dict(label=ttl, ls='None'), showflier=False\n",
    "    )\n",
    "    ax.set_xticks(np.arange(plot_df.shape[0]))\n",
    "    ax.set_xticklabels(list(plot_df.solver), rotation=0)\n",
    "\n",
    "### Decorate ###\n",
    "for ax in axs[:,0]: ax.set_ylabel('Rel. run time')\n",
    "axs.flat[0].legend(loc='upper right', frameon=True, bbox_to_anchor=(1,1.1), borderpad=0.2)\n",
    "pltu.tight_layout()\n",
    "sns.despine()\n",
    "pltu.grid(axs, axis='y')\n",
    "pltu.savefig('rel_run_times')\n",
    "pltu.show_saved_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for solver, group in plot_df.groupby(['solver'], sort=False):\n",
    "    method = solver.replace('\\mathrm', '').replace('$', '')\n",
    "    print(f\"{method} \\t {np.mean(np.concatenate(list(group.conrad_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adaptive, group in plot_df.groupby(['adaptive'], sort=False):\n",
    "    print(f\"{adaptive} \\t {np.mean(np.concatenate(list(group.conrad_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{adaptive} \\t {np.mean(np.concatenate(list(plot_df.conrad_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{adaptive} \\t {np.mean(np.concatenate(list(plot_df.abdulle_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{adaptive} \\t {np.mean(np.concatenate(list(plot_df.abdulleln_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for solver, group in plot_df.groupby(['solver'], sort=False):\n",
    "    method = solver.replace('\\mathrm', '').replace('$', '')\n",
    "    print(f\"{method} \\t {np.mean(np.concatenate(list(group.abdulle_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adaptive, group in plot_df.groupby(['adaptive'], sort=False):\n",
    "    print(f\"{adaptive} \\t {np.mean(np.concatenate(list(group.abdulle_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for solver, group in plot_df.groupby(['solver'], sort=False):\n",
    "    method = solver.replace('\\mathrm', '').replace('$', '')\n",
    "    print(f\"{method} \\t {np.mean(np.concatenate(list(group.abdulleln_rel_run_times)))*100:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adaptive, group in plot_df.groupby(['adaptive'], sort=False):\n",
    "    print(f\"{adaptive} \\t {np.mean(np.concatenate(list(group.abdulleln_rel_run_times)))*100:.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.949px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
